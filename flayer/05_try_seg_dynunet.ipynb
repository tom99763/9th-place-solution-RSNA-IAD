{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4915b6-91d6-49af-9d1b-e1658a346905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import amp\n",
    "\n",
    "from monai.transforms import (\n",
    "    Compose, MapTransform, EnsureTyped, ToTensord,\n",
    "    RandFlipd, RandRotate90d, RandGaussianNoised,\n",
    "    RandCropByPosNegLabeld,SpatialPadd,RandAffined\n",
    ")\n",
    "from monai.data import Dataset, DataLoader\n",
    "from monai.networks.nets import UNet, DynUNet\n",
    "from monai.losses import DiceFocalLoss, DeepSupervisionLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.utils import set_determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8774962-2572-4e12-95a9-d708222b6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "is_amp = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df998806-9e75-42ed-ad15-b754a42fcb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"spacing_07_p1_p99_v1\"  #\"spacing_07_p1_p99_v1\"\n",
    "DATA_ROOT   = f\"/ssd3/rsna_2025_flayer/input/{data_folder}\"\n",
    "IMG_DIR     = f\"{DATA_ROOT}/img\"\n",
    "MASK_DIR    = f\"{DATA_ROOT}/mask_b\"\n",
    "OUT_DIR     = \"model/seg\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126d849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_paths=glob.glob(f\"{IMG_DIR}/*.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308c14b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(npy_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e607a70-87ee-4390-b2c7-815f111cae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_SIZE    = (96,256,256)   # ()若還有餘裕，可試 (224, 256, 256) 或 (224, 288, 288)\n",
    "BATCH_SIZE  = 6                 # 96G 通常可到 4~6；不夠就降到 3/2\n",
    "NUM_WORKERS = 16\n",
    "MAX_EPOCHS  = 600 #450\n",
    "LR          = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b8caa-f953-4a3d-94a2-3a083e62fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 驗證時 sliding window 批量\n",
    "SW_BATCH    = 2                  # 96G 可設 2~4；推論只有 16G 時請改為 1\n",
    "SW_ROI      = ROI_SIZE           # 也可設更大 (224,256,256) 看顯存調整\n",
    "SW_OVERLAP  = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17045975-c4cd-473f-a522-1ab6c0023341",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def list_pairs(img_dir, mask_dir):\n",
    "    img_paths = sorted(glob.glob(os.path.join(img_dir, \"*.npy\")))\n",
    "    mask_paths = sorted(glob.glob(os.path.join(mask_dir, \"*.npy\")))\n",
    "    mask_map = {Path(p).stem: p for p in mask_paths}\n",
    "    pairs = []\n",
    "    for ip in img_paths:\n",
    "        key = Path(ip).stem\n",
    "        lp = mask_map.get(key)\n",
    "        if lp is None:\n",
    "            continue\n",
    "        pairs.append({\"image\": ip, \"label\": lp})\n",
    "    return pairs\n",
    "\n",
    "all_files = list_pairs(IMG_DIR, MASK_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c953fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_df=pd.read_csv(\"/ssd3/rsna_2025_flayer/input/train_with_folds_optimized_axis_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce4aa5-96bb-4d9c-beba-e048c9bcc83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_df = fold_df[fold_df[\"axis\"]==\"z\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a84a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fold_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7eb725-cc32-4932-a698-557326b12ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths=glob.glob(f\"/ssd3/rsna_2025_flayer/input/{data_folder}/img/*.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7528e869-6f01-4bbd-a5f4-a44f41c87626",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid_list=[Path(p).stem for p in img_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d1ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec02dc9-a612-460f-8dc3-7875ab7bd669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\"SeriesInstanceUID\":sid_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4692f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b3da82-38c4-48b1-a6ea-c1cb80c48a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(fold_df[[\"SeriesInstanceUID\",\"Modality\",\"fold\"]],on=\"SeriesInstanceUID\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b3ba1d-0fc9-4c5a-9ad7-dd3c434d8f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"img_path\"] = df[\"SeriesInstanceUID\"].apply(\n",
    "    lambda x: f\"/ssd3/rsna_2025_flayer/input/{data_folder}/img/{x}.npy\"\n",
    ")\n",
    "\n",
    "df[\"mask_path\"] = df[\"SeriesInstanceUID\"].apply(\n",
    "    lambda x: f\"/ssd3/rsna_2025_flayer/input/{data_folder}/mask_b/{x}.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f0fab-3ec4-4db7-a7b7-52007f7e6378",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(5):\n",
    "    d_p = df[df[\"fold\"]==fold]\n",
    "    print(\"*******\")\n",
    "    print(d_p[\"Modality\"].value_counts())\n",
    "    \n",
    "    print(\"*******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f80ba17-b9f6-4f9f-940b-46da2076e341",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Modality\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b82c185-da61-4818-a904-2dd12a2ad333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b0fcc-6ec4-4f30-a960-5af060f853d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0\n",
    "#fold2\n",
    "fold=1 #1\n",
    "train_df=df[df[\"fold\"]!=fold].reset_index(drop=True)\n",
    "valid_df=df[df[\"fold\"]==fold].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2aa3c2-18fa-4dca-8a5c-a1e73e288e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadNPYd(MapTransform):\n",
    "    def __init__(self, keys):\n",
    "        super().__init__(keys)\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for k in self.keys:\n",
    "            arr = np.load(d[k])\n",
    "            if arr.ndim == 3:\n",
    "                arr = arr[None, ...]  # -> [1,H,W,D]\n",
    "            if k == \"label\":\n",
    "                arr = (arr > 0.5).astype(np.float32)  # np.unit8\n",
    "            else:\n",
    "                arr = arr.astype(np.float32)\n",
    "            d[k] = arr\n",
    "        return d\n",
    "\n",
    "# ---------- 這個 helper 把 df 轉成 MONAI 需要的 list[dict] ----------\n",
    "def df_to_monai_list(df, img_col=\"img_path\", mask_col=\"mask_path\"):\n",
    "    df = df.copy()\n",
    "    df = df.rename(columns={img_col: \"image\", mask_col: \"label\"})\n",
    "    # 只保留有標註的列（若你有無標註資料，另做測試集）\n",
    "    df = df.dropna(subset=[\"image\", \"label\"])\n",
    "    return df[[\"image\", \"label\"]].to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f85f69-7f04-4e30-a3ee-8eb7ffbbe4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee07f9e-961d-4e8a-9e2c-859010ac57c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce35a2b-332a-49f6-81c8-eeca2fb29d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_files = df_to_monai_list(train_df, \"img_path\", \"mask_path\")\n",
    "val_files   = df_to_monai_list(valid_df,   \"img_path\", \"mask_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e414288e-cd1e-4fc8-b2d3-e90539f8bd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = np.load(train_files[0][\"image\"])\n",
    "in_channels = probe.shape[0] if probe.ndim == 4 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1f4075-167f-4509-a1af-e1302fc0b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43b092e-4aaa-4a6c-83ea-1130c9c27bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====== Transforms ======\n",
    "train_tf = Compose([\n",
    "    LoadNPYd(keys=[\"image\", \"label\"]),\n",
    "    SpatialPadd(keys=[\"image\",\"label\"], spatial_size=ROI_SIZE,method=\"symmetric\", mode=\"constant\", constant_values=0),\n",
    "    RandCropByPosNegLabeld(\n",
    "        keys=[\"image\",\"label\"], label_key=\"label\",\n",
    "        spatial_size=ROI_SIZE, pos=4.0, neg=0.25, num_samples=2,\n",
    "        image_key=\"image\", image_threshold=0.0\n",
    "    ),\n",
    "    RandFlipd(keys=[\"image\",\"label\"], prob=0.5, spatial_axis=[0]),\n",
    "    RandFlipd(keys=[\"image\",\"label\"], prob=0.5, spatial_axis=[1]),\n",
    "    RandFlipd(keys=[\"image\",\"label\"], prob=0.5, spatial_axis=[2]),\n",
    "    \n",
    "    RandAffined(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        prob=0.5,\n",
    "        rotate_range=(0.1, 0.1, 0.1),   # 弧度制 ≈ 5.7 度\n",
    "        scale_range=(0.05, 0.05, 0.05), # 輕微縮放 ±5%\n",
    "        translate_range=(10, 10, 10),   # 平移最多 10 voxel\n",
    "        mode=(\"bilinear\", \"nearest\")\n",
    "    ),\n",
    "    \n",
    "    \n",
    "    RandRotate90d(keys=[\"image\",\"label\"], prob=0.5, spatial_axes=(1,2)),\n",
    "    RandGaussianNoised(keys=[\"image\"], prob=0.15, mean=0.0, std=0.01),\n",
    "    EnsureTyped(keys=[\"image\",\"label\"]),\n",
    "    ToTensord(keys=[\"image\",\"label\"]),\n",
    "])\n",
    "\n",
    "val_tf = Compose([\n",
    "    LoadNPYd(keys=[\"image\", \"label\"]),\n",
    "    SpatialPadd(keys=[\"image\",\"label\"], spatial_size=ROI_SIZE,method=\"symmetric\", mode=\"constant\", constant_values=0),\n",
    "    EnsureTyped(keys=[\"image\",\"label\"]),\n",
    "    ToTensord(keys=[\"image\",\"label\"]),\n",
    "])\n",
    "\n",
    "# ====== Datasets / Loaders ======\n",
    "train_ds = Dataset(train_files, transform=train_tf)\n",
    "val_ds   = Dataset(val_files,   transform=val_tf)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=1, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4e8d0-dc9b-4d6a-a1a3-b3a49bee30be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====== Model / Loss / Optim ======\n",
    "# model = UNet(\n",
    "#     spatial_dims=3, in_channels=in_channels, out_channels=1,\n",
    "#     channels=(48, 96, 192, 384), strides=(2, 2, 2), num_res_units=2\n",
    "# ).to(device)\n",
    "\n",
    "\n",
    "# 依你的 ROI_SIZE/spacing 選一組 strides & filters（典型 nnU-Net 風格）\n",
    "# 這裡給 5 個層級，3D 全卷積；若顯存吃緊可把 filters 降一檔。\n",
    "strides = [\n",
    "    (1, 1, 1),   # level 0 (no downsample)\n",
    "    (2, 2, 2),   # level 1\n",
    "    (2, 2, 2),   # level 2\n",
    "    (2, 2, 2),   # level 3\n",
    "    (2, 2, 2),   # level 4\n",
    "]\n",
    "kernel_size = [(3,3,3)] * len(strides)\n",
    "upsample_kernel_size = strides[1:]\n",
    "\n",
    "filters = [32, 64, 128, 256, 320]   # nnU-Net 風格；你有 96GB，這組很穩\n",
    "\n",
    "model = DynUNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=in_channels,\n",
    "    out_channels=1,\n",
    "    kernel_size=kernel_size,\n",
    "    strides=strides,\n",
    "    upsample_kernel_size=upsample_kernel_size,\n",
    "    filters=filters,\n",
    "    dropout=0.0,\n",
    "    deep_supervision=True,   # 啟用深度監督\n",
    "    deep_supr_num=3,         # 最高層之外再用 3 個低解析輸出做監督\n",
    ").to(device)\n",
    "\n",
    "#loss_fn   = DiceFocalLoss(sigmoid=True, lambda_dice=0.7, lambda_focal=0.3, gamma=2.0)\n",
    "\n",
    "\n",
    "base_loss = DiceFocalLoss(\n",
    "    sigmoid=True,\n",
    "    lambda_dice=0.7,      # 初期偏 Dice 更穩；之後可回 0.7/0.3\n",
    "    lambda_focal=0.3,\n",
    "    gamma=2.0,\n",
    "    smooth_nr=1e-5, smooth_dr=1e-5,\n",
    "    include_background=False,\n",
    ")\n",
    "\n",
    "# 權重給「高解析 > 低解析」，exp 會自動衰減（也可傳自訂 weights list）\n",
    "loss_fn = DeepSupervisionLoss(base_loss, weight_mode=\"exp\")\n",
    "\n",
    "opt       = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "\n",
    "scaler = amp.GradScaler(enabled = is_amp)\n",
    "dice_meter= DiceMetric(include_background=False, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad56fb19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd91359-e195-4b10-886d-ad5d0696d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ====== Validate (sliding-window 全圖) ======\n",
    "\n",
    "THRESH_LIST = [0.1, 0.3, 0.5]\n",
    "\n",
    "\n",
    "def predictor_highest(x):\n",
    "    out = model(x)\n",
    "    return out[0] if isinstance(out, (list, tuple)) else out\n",
    "@torch.no_grad()\n",
    "def validate():\n",
    "    model.eval()\n",
    "    meters = {t: DiceMetric(include_background=False, reduction=\"mean\") for t in THRESH_LIST}\n",
    "    has_fg = 0\n",
    "    \n",
    "    for batch in val_loader:\n",
    "        img, msk = batch[\"image\"].to(device, non_blocking=True), batch[\"label\"].to(device, non_blocking=True)\n",
    "        \n",
    "        \n",
    "\n",
    "        logits = sliding_window_inference(\n",
    "            img, roi_size=ROI_SIZE, sw_batch_size=SW_BATCH,\n",
    "            predictor=predictor_highest, overlap=0.5, mode=\"gaussian\"\n",
    "        )\n",
    "        prob = torch.sigmoid(logits)\n",
    "\n",
    "        if msk.sum().item() == 0: continue\n",
    "        has_fg += 1\n",
    "        for t,m in meters.items():\n",
    "            m(y_pred=(prob>t).float(), y=msk)\n",
    "\n",
    "    if has_fg==0: return {\"best_t\": None, \"dice_by_t\": {t:0.0 for t in THRESH_LIST}}\n",
    "    dice_by_t = {t:m.aggregate().item() for t,m in meters.items()}\n",
    "    best_t = max(dice_by_t, key=dice_by_t.get)\n",
    "    return {\"best_t\": best_t, \"dice_by_t\": dice_by_t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d8cd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job=13 #13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de08f523-9c3a-43c8-8370-9443044b1f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Train Loop ======\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=4e-4, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(opt, T_max=MAX_EPOCHS, eta_min=1e-6)\n",
    "\n",
    "\n",
    "\n",
    "best_score = 0.0\n",
    "for ep in range(1, MAX_EPOCHS + 1):\n",
    "    model.train(); running = 0.0\n",
    "    for batch in train_loader:\n",
    "        img = batch[\"image\"].to(device, non_blocking=True)\n",
    "        msk = batch[\"label\"].to(device, non_blocking=True)\n",
    "        #print(msk.unique())\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(\"cuda\", enabled=is_amp):\n",
    "            out = model(img)  # DynUNet deep supervision 輸出\n",
    "    \n",
    "            if isinstance(out, torch.Tensor) and out.dim() == 6:\n",
    "                # 拆成 list: [ [B,1,H,W,D], ...共4個]\n",
    "                logits_list = [out[:, i, ...] for i in range(out.shape[1])]\n",
    "            elif isinstance(out, (list, tuple)):\n",
    "                logits_list = list(out)\n",
    "            else:\n",
    "                logits_list = [out]\n",
    "\n",
    "            # 確保 label 是 float32 且 shape [B,1,H,W,D]\n",
    "            msk = msk.float()\n",
    "            loss = loss_fn(logits_list, msk)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt); scaler.update()\n",
    "        running += loss.item() * img.size(0)\n",
    "\n",
    "    if scheduler: scheduler.step()\n",
    "\n",
    "    tr_loss = running / len(train_loader.dataset)\n",
    "    val_stats = validate()  # ← 每次調用都會各自 reset meters\n",
    "    line = \" \".join([f\"{t:.1f}:{val_stats['dice_by_t'][t]:.4f}\" for t in THRESH_LIST])\n",
    "    print(f\"Epoch {ep:03d} | lr={opt.param_groups[0]['lr']:.2e} | train_loss={tr_loss:.4f} | val_dice@ {line} | best_t={val_stats['best_t']}\")\n",
    "\n",
    "    # 用最佳閾值的 Dice 當 early-select 指標\n",
    "    if val_stats[\"best_t\"] is not None:\n",
    "        cur_best = val_stats[\"dice_by_t\"][val_stats[\"best_t\"]]\n",
    "        if cur_best > best_score:\n",
    "            best_score = cur_best\n",
    "            torch.save(model.state_dict(), os.path.join(OUT_DIR, f\"job{job}_fold{fold}_best.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a613b32-6dbb-4b51-acfc-46b1438112b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ca572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

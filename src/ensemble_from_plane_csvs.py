"""
Ensemble three plane-level prediction CSVs (axial, coronal, sagittal) by averaging
their per-series probabilities, and optionally compute overall and location AUCs.

Usage:
  python -m src.ensemble_from_plane_csvs \
    --csv path/to/axial_predictions.csv path/to/coronal_predictions.csv path/to/sagittal_predictions.csv \
    --out-csv path/to/ensemble_predictions.csv

Notes:
 - Expects each CSV to contain columns: SeriesInstanceUID, aneurysm_prob, true_label (optional)
 - If columns loc_prob_0..loc_prob_12 are present, they will be averaged and saved.
 - If true_label is present and both classes exist, AUROC is computed.
 - If location ground-truth columns are available in train_df.csv (via configs.data_config.data_path),
   a location macro AUC is computed as well.
"""
from __future__ import annotations

import argparse
from pathlib import Path
import sys
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
from sklearn.metrics import roc_auc_score


# Project root and data config
ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(ROOT / 'src'))
try:
    from configs.data_config import data_path  # type: ignore
except Exception:
    data_path = None


LABELS_TO_IDX = {
    'Anterior Communicating Artery': 0,
    'Basilar Tip': 1,
    'Left Anterior Cerebral Artery': 2,
    'Left Infraclinoid Internal Carotid Artery': 3,
    'Left Middle Cerebral Artery': 4,
    'Left Posterior Communicating Artery': 5,
    'Left Supraclinoid Internal Carotid Artery': 6,
    'Other Posterior Circulation': 7,
    'Right Anterior Cerebral Artery': 8,
    'Right Infraclinoid Internal Carotid Artery': 9,
    'Right Middle Cerebral Artery': 10,
    'Right Posterior Communicating Artery': 11,
    'Right Supraclinoid Internal Carotid Artery': 12,
}
LOCATION_LABELS = sorted(list(LABELS_TO_IDX.keys()))
N_LOC = len(LOCATION_LABELS)


def parse_args():
    ap = argparse.ArgumentParser(description="Ensemble plane CSV predictions")
    ap.add_argument('--csv', nargs='+', required=True,
                    help='Three CSV paths generated by validation (axial, coronal, sagittal). Extra CSVs are allowed; missing ones are ignored.')
    ap.add_argument('--out-csv', type=str, default='ensemble_predictions.csv',
                    help='Output CSV path for ensemble predictions')
    ap.add_argument('--save-json', type=str, default='', help='Optional JSON summary path')
    return ap.parse_args()


def load_csvs(csv_paths: List[Path]) -> List[Tuple[Path, pd.DataFrame]]:
    items: List[Tuple[Path, pd.DataFrame]] = []
    for p in csv_paths:
        if not p.exists():
            print(f"Warning: CSV not found, skipping: {p}")
            continue
        try:
            df = pd.read_csv(p)
            # Basic column presence check
            if 'SeriesInstanceUID' not in df.columns or 'aneurysm_prob' not in df.columns:
                print(f"Warning: CSV missing required columns, skipping: {p}")
                continue
            items.append((p, df))
        except Exception as e:
            print(f"Warning: Failed to read {p}: {e}")
    return items


def detect_plane_from_path(path: Path) -> str:
    s = str(path).lower()
    if 'axial' in s:
        return 'axial'
    if 'coronal' in s:
        return 'coronal'
    if 'sagittal' in s:
        return 'sagittal'
    # fallback to stem
    return path.stem


def compute_csv_metrics(df: pd.DataFrame) -> Tuple[float, float]:
    """Return (cls_auc, loc_macro_auc). Values may be NaN if not computable."""
    # Classification AUC
    cls_auc = float('nan')
    if 'label_aneurysm' in df.columns:
        try:
            sub = df[['label_aneurysm', 'aneurysm_prob']].dropna()
            y = sub['label_aneurysm'].astype(int).tolist()
            s = sub['aneurysm_prob'].astype(float).tolist()
            if len(y) > 0 and len(set(y)) > 1:
                cls_auc = float(roc_auc_score(y, s))
        except Exception:
            pass

    # Location macro AUC using GT from train_df if available
    loc_macro_auc = float('nan')
    has_loc_cols = all((f'loc_prob_{i}' in df.columns) for i in range(N_LOC))
    if has_loc_cols and data_path is not None:
        try:
            data_root = Path(data_path)
            train_csv = data_root / 'train_df.csv'
            if not train_csv.exists():
                train_csv = data_root / 'train.csv'
            if train_csv.exists():
                tr = pd.read_csv(train_csv).set_index('SeriesInstanceUID')
                rows = []
                preds = []
                for _, r in df.iterrows():
                    sid = r['SeriesInstanceUID']
                    if sid in tr.index:
                        gt = []
                        trr = tr.loc[sid]
                        for name in LOCATION_LABELS:
                            try:
                                gt.append(float(trr.get(name, 0.0)))
                            except Exception:
                                gt.append(0.0)
                        pr = [float(r[f'loc_prob_{i}']) for i in range(N_LOC)]
                        rows.append(gt)
                        preds.append(pr)
                if rows:
                    y_true = np.asarray(rows, dtype=float)
                    y_pred = np.asarray(preds, dtype=float)
                    per_loc = []
                    for i in range(N_LOC):
                        try:
                            per_loc.append(roc_auc_score(y_true[:, i], y_pred[:, i]))
                        except Exception:
                            per_loc.append(float('nan'))
                    loc_macro_auc = float(np.nanmean(per_loc))
        except Exception:
            pass

    return cls_auc, loc_macro_auc


def ensemble_from_dfs(dfs: List[pd.DataFrame]):
    ensemble_probs: Dict[str, List[float]] = {}
    true_labels: Dict[str, int] = {}
    loc_probs: Dict[str, List[List[float]]] = {}

    for df in dfs:
        for _, row in df.iterrows():
            sid = row['SeriesInstanceUID']
            prob = float(row['aneurysm_prob'])
            label = row.get('label_aneurysm')
            if sid not in ensemble_probs:
                ensemble_probs[sid] = []
                # prefer the first seen label
                if pd.notna(label):
                    try:
                        true_labels[sid] = int(label)
                    except Exception:
                        pass
            ensemble_probs[sid].append(prob)

            # collect location probabilities if present
            loc_vec: List[float] = []
            has_loc = True
            for i in range(N_LOC):
                col = f'loc_prob_{i}'
                if col in df.columns:
                    try:
                        loc_vec.append(float(row[col]))
                    except Exception:
                        loc_vec.append(float('nan'))
                else:
                    has_loc = False
                    break
            if has_loc:
                loc_probs.setdefault(sid, []).append(loc_vec)

    # finalize averages
    final_rows = []
    final_scores: List[float] = []
    final_y: List[int] = []
    final_loc_avg: Dict[str, List[float]] = {}

    for sid, probs in ensemble_probs.items():
        if not probs:
            continue
        avg = float(np.nanmean(np.asarray(probs, dtype=float)))
        row = {
            'SeriesInstanceUID': sid,
            'ensemble_prob': avg,
            'label_aneurysm': true_labels.get(sid, np.nan),
            'num_planes': len([p for p in probs if pd.notna(p)]),
        }
        if sid in loc_probs and len(loc_probs[sid]) > 0:
            arr = np.asarray(loc_probs[sid], dtype=float)
            avg_loc = list(np.nanmean(arr, axis=0))
            for i in range(N_LOC):
                row[f'loc_prob_{i}'] = float(avg_loc[i])
            final_loc_avg[sid] = avg_loc
        final_rows.append(row)
        # labels for AUC
        if sid in true_labels:
            final_scores.append(avg)
            final_y.append(true_labels[sid])

    out_df = pd.DataFrame(final_rows)

    # classification AUC
    cls_auc = float('nan')
    if final_y and len(set(final_y)) > 1:
        try:
            cls_auc = float(roc_auc_score(final_y, final_scores))
        except Exception as e:
            print(f"AUC computation failed: {e}")

    # location macro AUC (requires ground truth location columns from train_df)
    loc_macro_auc = float('nan')
    if final_loc_avg and data_path is not None:
        try:
            data_root = Path(data_path)
            train_csv = data_root / 'train_df.csv'
            if not train_csv.exists():
                train_csv = data_root / 'train.csv'
            if train_csv.exists():
                tr = pd.read_csv(train_csv).set_index('SeriesInstanceUID')
                y_true = []
                y_pred = []
                for sid, pred_vec in final_loc_avg.items():
                    if sid in tr.index:
                        gt_vec = []
                        row = tr.loc[sid]
                        for name in LOCATION_LABELS:
                            try:
                                gt_vec.append(float(row.get(name, 0.0)))
                            except Exception:
                                gt_vec.append(0.0)
                        y_true.append(gt_vec)
                        y_pred.append(pred_vec)
                if y_true:
                    y_true = np.asarray(y_true, dtype=float)
                    y_pred = np.asarray(y_pred, dtype=float)
                    per_loc = []
                    for i in range(N_LOC):
                        try:
                            per_loc.append(roc_auc_score(y_true[:, i], y_pred[:, i]))
                        except Exception:
                            per_loc.append(float('nan'))
                    loc_macro_auc = float(np.nanmean(per_loc))
        except Exception as e:
            print(f"Location AUC computation failed: {e}")

    return out_df, cls_auc, loc_macro_auc


def main():
    args = parse_args()
    csv_paths = [Path(p) for p in args.csv]
    items = load_csvs(csv_paths)
    if len(items) == 0:
        print("No valid CSVs provided. Nothing to do.")
        return

    # Per-plane (axis) metrics
    print("Per-plane (axis) metrics:")
    per_input_summary = []
    for p, df in items:
        plane = detect_plane_from_path(p)
        cls_auc_i, loc_auc_i = compute_csv_metrics(df)
        n_series = int(df.shape[0])
        print(f"  - {plane}: n={n_series}, cls_auc={cls_auc_i if not np.isnan(cls_auc_i) else 'nan'}, loc_macro_auc={loc_auc_i if not np.isnan(loc_auc_i) else 'nan'}")
        per_input_summary.append({
            'plane': plane,
            'path': str(p),
            'n_series': n_series,
            'cls_auc': cls_auc_i,
            'loc_macro_auc': loc_auc_i,
        })

    # Ensemble across provided CSVs
    dfs = [df for _, df in items]
    out_df, cls_auc, loc_macro_auc = ensemble_from_dfs(dfs)
    out_path = Path(args.out_csv)
    out_path.parent.mkdir(parents=True, exist_ok=True)
    out_df.to_csv(out_path, index=False)

    print(f"Saved ensemble predictions to: {out_path}")
    if not np.isnan(cls_auc):
        print(f"Ensemble Classification AUC: {cls_auc:.4f}")
    else:
        print("Ensemble Classification AUC: nan (insufficient label diversity or labels missing)")
    if not np.isnan(loc_macro_auc):
        print(f"Ensemble Location macro AUC: {loc_macro_auc:.4f}")
    else:
        print("Ensemble Location macro AUC: nan (ground truth not found or insufficient)")

    if args.save_json:
        import json
        summary = {
            'num_inputs': len(dfs),
            'out_csv': str(out_path),
            'cls_auc': cls_auc,
            'loc_macro_auc': loc_macro_auc,
            'num_series': int(out_df.shape[0]),
            'per_inputs': per_input_summary,
        }
        with open(args.save_json, 'w') as f:
            json.dump(summary, f, indent=2)
        print(f"Saved summary JSON to: {args.save_json}")


if __name__ == '__main__':
    main()



#python3 -m src.ensemble_from_plane_csvs --csv yolo_planes/exp-yolo11m_allviews_fold02/validation_results/axial_predictions.csv yolo_planes/exp-yolo11m_allviews_fold02/validation_results/coronal_predictions.csv yolo_planes/exp-yolo11m_allviews_fold02/validation_results/sagittal_predictions.csv --out-csv yolo_planes/exp-yolo11m_allviews_fold02/validation_results/ensemble_predictions.csv --save-json yolo_planes/exp-yolo11m_allviews_fold02/validation_results/ensemble_summary.json
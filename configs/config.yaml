# conf/config.yaml
# These are some base parameters for the experiment
project_name: "rsna-iad-yolo-gnn"

data_dir: ./src/data
seed: 42
fold_id: 1

batch_size: 8
num_workers: 4
experiment: ${graph_type}_${model.num_layers}l_${model.hidden_channels}_${model.jk}_${model.pooling}_fold${fold_id}

#model config
walk_length: 8
k_neibs: 15
graph_type: knn_graph
use_pe: false

# loss settings
pos_weight: 8          # depends on imbalance ratio
lambda_graph: 1.0
lambda_consistency: 1.0
lambda_ranking: 1.0
margin: 1.0

# Balanced sampling configuration
use_balanced_sampling: true  # Set to true to enable balanced pos/neg sampling
pos_ratio: 0.5  # 0.5 with batch_size 4 = 2 positive + 2 negative per batch
image_mode: "2.5D"
use_wandb: true  # Set to false to disable WandB logging

# WandB settings (only used if use_wandb: true)
wandb:
  entity: null  # Auto-detect from logged-in user
  tags: ["tf_efficientnetv2_b0.in1k", "fold_${fold_id}"]
  notes: "efficientnet_v2 on 2.5D slices"


# The 'defaults' list tells Hydra which configs to load by default.
# It will look for 'lightgbm.yaml' inside the 'model' sub-directory.
defaults:
  - model: GraphModel
  - optimizer: AdamW
  - trainer: default
  - _self_


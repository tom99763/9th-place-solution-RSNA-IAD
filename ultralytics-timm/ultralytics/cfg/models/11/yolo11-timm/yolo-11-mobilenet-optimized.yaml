nc: 80
scales:
  # [depth_multiple, width_multiple, max_channels]
  n: [1.00, 1.00, 1024]  # Increased to 1024 to accommodate 960ch backbone


# Backbone feature extraction:
# Feature 0: [32, 480, 480]   - Skip (too large)
# Feature 1: [48, 240, 240]   - Skip (too large)
# Feature 2: [80, 120, 120]   - P3 for small objects
# Feature 3: [160, 60, 60]    - P4 for medium objects
# Feature 4: [960, 30, 30]    - P5 for large objects

backbone:
  # Load MobileNetV4 with pretrained weights
  - [-1, 1, Timm, [960, 'mobilenetv4_hybrid_medium.ix_e550_r384_in1k', True, True, 0, True]]
  
  # Extract multi-scale features
  - [0, 1, Index, [80, 2]]      # P3 → 80 ch @ 120×120
  - [0, 1, Index, [160, 3]]     # P4 → 160 ch @ 60×60
  - [0, 1, Index, [960, 4]]     # P5 → 960 ch @ 30×30
  
  # Enhance P5 features
  - [-1, 1, SPPF, [512, 5]]     # Reduce 960→512 for efficiency
  - [-1, 2, C2PSA, [512]]       # Keep at 512


# ============================================================================
# HEAD DESIGN RULES:
# ============================================================================
# 
# TOP-DOWN PATH (Large → Small objects, adding spatial detail):
#   - Upsample higher-level features
#   - Concat with backbone features (skip connections)
#   - Reduce channels to manageable size
#
# BOTTOM-UP PATH (Small → Large objects, adding semantic info):
#   - Downsample lower-level features  
#   - Concat with top-down processed features
#   - Match or exceed backbone channel counts for detection
#
# CHANNEL CALCULATION:
#   - After concat: choose output based on target detection level
#   - P3 final: ~128-256ch (small objects need less semantic info)
#   - P4 final: ~256-512ch (medium objects - balanced)
#   - P5 final: ~512-1024ch (large objects need strong semantics)
# ============================================================================

head:
  # ===== TOP-DOWN PATH =====
  
  # Stage 1: P5 → P4
  - [5,    1, nn.Upsample, [None, 2, "nearest"]]   # 6: 512ch @ 60×60
  - [[6, 2], 1, Concat,        [1]]                # 7: 512+160 = 672ch
  - [7,    2, C3k2,            [256, False]]       # 8: 672→256ch (reduce for P4)
  
  # Stage 2: P4 → P3  
  - [8,    1, nn.Upsample, [None, 2, "nearest"]]   # 9: 256ch @ 120×120
  - [[9, 1], 1, Concat,       [1]]                 # 10: 256+80 = 336ch
  - [10,   2, C3k2,            [128, False]]       # 11: 336→128ch (P3 output)
  
  
  # ===== BOTTOM-UP PATH =====
  
  # Stage 3: P3 → P4
  - [11,   1, Conv,            [128, 3, 2]]        # 12: 128ch @ 60×60
  - [[12, 8], 1, Concat,       [1]]                # 13: 128+256 = 384ch
  - [13,   2, C3k2,            [256, False]]       # 14: 384→256ch (P4 output)
  
  # Stage 4: P4 → P5
  - [14,   1, Conv,            [256, 3, 2]]        # 15: 256ch @ 30×30
  - [[15, 5], 1, Concat,       [1]]                # 16: 256+512 = 768ch
  - [16,   2, C3k2,            [512, True]]        # 17: 768→512ch (P5 output)
  
  
  # ===== DETECTION HEAD =====
  # Final detection on [P3=128ch, P4=256ch, P5=512ch]
  - [[11, 14, 17], 1, Detect,   [nc]]


# ============================================================================
# DESIGN RATIONALE:
# ============================================================================
#
# 1. BACKBONE ADAPTATION:
#    - MobileNetV4 outputs [80, 160, 960] vs YOLO11's [256, 512, 1024]
#    - Reduced P5 from 960→512 with SPPF for computational efficiency
#    - Kept max_channels=1024 to allow full backbone capacity
#
# 2. HEAD CHANNEL CHOICES:
#    - P3: 128ch (small objects, focus on spatial precision)
#    - P4: 256ch (medium objects, balanced features)  
#    - P5: 512ch (large objects, strong semantic features)
#
# 3. CONCAT STRATEGY:
#    - Top-down: Progressive reduction (512→256→128)
#    - Bottom-up: Progressive increase (128→256→512)
#    - Each stage roughly doubles/halves channels
#
# 4. COMPARISON TO STANDARD YOLO11:
#    - Standard YOLO11-n: [256, 512, 1024] → [256, 512, 1024]
#    - This config: [80, 160, 960] → [128, 256, 512]
#    - Proportionally similar, adapted to smaller backbone
#
# ============================================================================

